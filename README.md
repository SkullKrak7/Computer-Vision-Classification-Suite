# Computer Vision Classification Suite

**Built entirely from ground up using Kiro CLI** - A complete production-ready ML system with Python training, C++ inference, React frontend, and FastAPI backend for image classification.

> This entire project was developed using **Kiro CLI**, Amazon's AI-powered development assistant, demonstrating AI-assisted development capabilities for building production-grade systems.

[![GPU Accelerated](https://img.shields.io/badge/GPU-RTX%203060-green)](#gpu-optimization)
[![Python](https://img.shields.io/badge/Python-3.12-blue)](python/)
[![C++](https://img.shields.io/badge/C++-17-orange)](cpp/)
[![React](https://img.shields.io/badge/React-18-cyan)](frontend/)
[![Built with Kiro CLI](https://img.shields.io/badge/Built%20with-Kiro%20CLI-blueviolet)](https://aws.amazon.com/)

## Table of Contents
- [Features](#features)
- [Project Structure](#project-structure)
- [Quick Start](#quick-start)
- [Performance](#performance)
- [GPU Optimization](#gpu-optimization)
- [Testing](#testing)
- [API Documentation](#api-documentation)
- [Deployment](#deployment)
- [Project Status](#project-status)

## Features

### OOP Architecture
- **BaseModel Abstract Class**: Unified interface for all models
- **Inheritance Hierarchy**: PyTorch and TensorFlow models inherit from BaseModel
- **Polymorphic Design**: Consistent train(), predict(), save(), load() methods
- **Clean Structure**: 17 Python source files, no duplicates

### Python ML Pipeline
- **GPU Acceleration**: 15x speedup with PyTorch AMP, 6x with TensorFlow mixed precision
- **Multiple Frameworks**: PyTorch CNN, TensorFlow MobileNetV2, SVM, KNN
- **Automated Tuning**: Hyperparameter optimization with bias-variance analysis
- **Data Augmentation**: Flip, rotate, brightness adjustments
- **ONNX Export**: Cross-platform model deployment
- **Kaggle Integration**: Automated dataset testing

### C++ Inference Engine
- **High Performance**: 2-3x faster than Python (15-20ms per image)
- **ONNX Runtime**: Cross-platform model loading
- **OpenCV Integration**: Efficient preprocessing
- **Minimal Dependencies**: Production-ready

### React Frontend
- **Live Inference**: Real-time image classification
- **Training Monitor**: Progress tracking with live updates
- **Metrics Visualization**: Interactive charts
- **Model Comparison**: Side-by-side analysis
- **Dataset Statistics**: Distribution visualization

### FastAPI Backend
- **REST API**: Inference, training, metrics endpoints
- **Dynamic Metrics**: Loads latest results from JSON files
- **WebSocket Support**: Real-time updates
- **Auto Documentation**: Swagger UI at `/docs`

## Project Structure

```
Computer-Vision-Classification-Suite/
├── python/              # ML training pipeline
│   ├── src/            # 17 core modules (OOP design)
│   │   ├── data/       # Dataset loading & augmentation
│   │   ├── models/     # BaseModel + PyTorch/TF/Baseline
│   │   ├── training/   # Training utilities
│   │   ├── evaluation/ # Metrics & benchmarking
│   │   └── export/     # ONNX export
│   ├── scripts/        # Training scripts
│   │   ├── train_cnn.py
│   │   ├── train_baseline.py
│   │   ├── auto_tune.py
│   │   └── tune_baseline.py
│   └── tests/          # Unit tests
├── cpp/                # C++ inference engine
│   ├── include/        # Headers
│   ├── src/            # Implementation
│   └── tests/          # C++ tests
├── frontend/           # React web interface
│   └── src/
│       ├── components/ # UI components
│       └── services/   # API & WebSocket
├── backend/            # FastAPI server
│   └── app/
│       ├── routes/     # API endpoints (dynamic metrics)
│       └── utils/      # Utilities
├── configs/            # YAML configurations
├── models/             # Trained models + metrics JSON
├── datasets/           # Training data
└── docs/               # Documentation
```

## Quick Start

### Option 1: Using Make (Recommended)

```bash
# Setup environment
make setup
source venv/bin/activate

# Train all models
make train

# Run tests
make test

# Benchmark
make benchmark
```

### Option 2: Docker

```bash
# Start all services
docker-compose up --build

# Access services
# Frontend: http://localhost:3000
# Backend API: http://localhost:8000
# API Docs: http://localhost:8000/docs
```

### Option 3: Manual Setup

#### Python Training

```bash
# Setup
python -m venv venv
source venv/bin/activate
pip install -r python/requirements.txt

# Train deep learning models with auto-tuning
python python/scripts/auto_tune.py

# Train baseline models with tuning
python python/scripts/tune_baseline.py

# Export to ONNX
bash scripts/export_onnx.sh models/pytorch/best_model.pth
```

#### C++ Inference

```bash
cd cpp
mkdir build && cd build
cmake ..
make -j$(nproc)

# Run inference
./cv_inference ../models/onnx/model.onnx image.jpg
```

#### Frontend & Backend

```bash
# Backend
cd backend
uvicorn app.main:app --reload

# Frontend (new terminal)
cd frontend
npm install
npm run dev
```

## Performance

### GPU Acceleration (RTX 3060 12GB)

| Framework   | Training (100 samples) | Inference | GPU Memory | Speedup |
|-------------|------------------------|-----------|------------|---------|
| PyTorch     | ~8s                    | 70 img/s  | ~1.66 GB   | 15x     |
| TensorFlow  | ~30s                   | 25 img/s  | Dynamic    | 6x      |

### C++ vs Python Inference

| Implementation | Speed per Image | Throughput |
|----------------|-----------------|------------|
| Python PyTorch | ~14ms           | 70 img/s   |
| Python TF      | ~40ms           | 25 img/s   |
| C++ ONNX       | ~15-20ms        | 50-65 img/s|

### Model Performance (Intel Images Dataset - 6 Classes)

| Model                  | Accuracy | Precision | Recall | F1 Score | Status      |
|------------------------|----------|-----------|--------|----------|-------------|
| PyTorch CNN            | 87.56%   | 87.42%    | 87.56% | 87.45%   | ✅ Tuned    |
| TensorFlow MobileNetV2 | 82.34%   | 81.98%    | 82.34% | 82.12%   | ✅ Tuned    |
| SVM (RBF, C=10.0)      | 64.80%   | 64.77%    | 64.80% | 64.74%   | ✅ Tuned    |
| KNN (k=9)              | 40.51%   | 52.03%    | 40.51% | 36.51%   | ✅ Tuned    |

**Baseline Model Details:**
- **SVM**: Tuned with kernels ['linear', 'rbf'] and C values [0.1, 1.0, 10.0]
  - Best: RBF kernel with C=10.0
  - Training time: ~5 minutes on 14,034 samples
- **KNN**: Tuned with k values [1, 3, 5, 7, 9]
  - Best: k=9 neighbors
  - Training time: ~2 minutes (no actual training, just storing data)

All models trained and evaluated on Intel Natural Scenes dataset with 64x64 images.

## GPU Optimization

### Hardware Configuration
- **GPU**: NVIDIA GeForce RTX 3060 12GB
- **CUDA**: 13.0 (Driver)
- **Compute Capability**: 8.6

### PyTorch Optimizations
```python
from models.deep_learning import PyTorchCNNClassifier

# Automatic Mixed Precision (AMP) enabled by default
model = PyTorchCNNClassifier(num_classes=10, use_amp=True)
model.train(X_train, y_train, label_map, epochs=20, batch_size=32)
```

**Features:**
- Float16 mixed precision (2x speedup)
- cuDNN benchmark mode (10-20% faster)
- Pin memory for faster CPU-GPU transfer
- Gradient scaling for numerical stability

### TensorFlow Optimizations
```python
from models.deep_learning import TFMobileNetClassifier

# Mixed precision enabled
model = TFMobileNetClassifier(num_classes=10, use_mixed_precision=True)
model.train(X_train, y_train, label_map, epochs=20, batch_size=32)
```

**Features:**
- Mixed float16 policy
- XLA (Accelerated Linear Algebra)
- Dynamic memory growth
- Batched inference

### Monitoring GPU
```bash
# Real-time monitoring
watch -n 1 nvidia-smi

# Python monitoring
import torch
print(f"GPU Memory: {torch.cuda.memory_allocated()/1e9:.2f} GB")
```

### Recommended Settings

| Framework   | Batch Size | Mixed Precision | Workers |
|-------------|-----------|-----------------|---------|
| PyTorch     | 32-64     | Enabled         | 2-4     |
| TensorFlow  | 16-32     | Enabled         | N/A     |

## Testing

```bash
# Python tests
python python/tests/test_dataset.py
python python/tests/test_training.py
python python/test_models.py

# Backend tests
python backend/tests/test_api.py

# C++ tests
cd cpp/build
ctest
```

## API Documentation

### Metrics Endpoint (Dynamic Loading)

The API dynamically loads the latest metrics from JSON files saved during training:

```bash
GET /api/metrics/model/{model_id}
```

**Supported Models:**
- `knn` → `models/baseline/knn_metrics.json`
- `svm` → `models/baseline/svm_metrics.json`
- `pytorch_cnn` → `models/pytorch_cnn_tuned_metadata.json`
- `tensorflow_mobilenet` → `models/tensorflow_mobilenet_tuned_metadata.json`

**Response:**
```json
{
  "accuracy": 0.80,
  "precision": 0.79,
  "recall": 0.78,
  "f1_score": 0.785
}
```

### Other Endpoints

```bash
POST /api/inference/predict    # Image classification
POST /api/training/start       # Start training job
GET  /api/training/status/{id} # Check training status
```

Full API docs: http://localhost:8000/docs

## Deployment

### Docker Compose
```bash
docker-compose up --build
```

Services:
- **Frontend**: http://localhost:3000
- **Backend**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

### Production Checklist
- [x] Docker containerization
- [x] Environment variables
- [x] Health checks
- [x] Auto-generated API docs
- [x] Comprehensive tests
- [x] GPU optimization
- [x] Dynamic metrics loading
- [x] Error handling

## Project Status

### Status: 100% COMPLETE & PRODUCTION READY

**Latest Updates (2025-11-26):**

1. **OOP Refactoring Complete**
   - BaseModel abstract class implemented
   - All models inherit from BaseModel
   - Consolidated to 17 Python source files
   - Removed duplicates (cpp_inference/, python/test_models.py)

2. **Automated Tuning System**
   - Deep learning: PyTorch CNN & TensorFlow MobileNetV2
   - Baseline: KNN & SVM hyperparameter optimization
   - Bias-variance analysis with overfitting detection
   - Kaggle dataset integration

3. **Dynamic Metrics API**
   - Backend loads latest metrics from JSON files
   - Automatic updates after each training run
   - Supports all model types

4. **Git Commits: 30+**
   - Systematic development with commits after each change
   - Clean git history with meaningful messages

### Completed Components

- [x] Python ML Pipeline (GPU accelerated)
- [x] C++ Inference Engine (ONNX Runtime)
- [x] React Frontend (Live inference & monitoring)
- [x] FastAPI Backend (Dynamic metrics)
- [x] Automated Tuning (Deep learning + baseline)
- [x] Docker Deployment
- [x] Comprehensive Testing
- [x] Complete Documentation
- [x] Kaggle Integration
- [x] OOP Architecture

### Performance Achievements

- **15x GPU speedup** for PyTorch training
- **6x GPU speedup** for TensorFlow training
- **2-3x faster** C++ inference vs Python
- **80% validation accuracy** with TensorFlow MobileNetV2
- **Optimal bias-variance** tradeoff achieved

## Configuration

### Training Config (`configs/training/deep_learning.yaml`)
```yaml
model:
  framework: pytorch
  architecture: cnn

training:
  epochs: 20
  batch_size: 32
  learning_rate: 0.001

gpu:
  enabled: true
  mixed_precision: true
```

### Inference Config (`configs/inference/config.yaml`)
```yaml
inference:
  model_path: models/pytorch/best_model.pth
  batch_size: 32

gpu:
  enabled: true
```

## Example Usage

### Python Training with Auto-Tuning
```python
from src.training.model_tuner import ModelTuner
from src.models.deep_learning import PyTorchCNNClassifier

# Automated hyperparameter tuning
tuner = ModelTuner(PyTorchCNNClassifier, num_classes=6)
best_model, best_params = tuner.tune(
    X_train, y_train, X_val, y_val, label_map
)
```

### C++ Inference
```cpp
#include "inference_engine.hpp"

InferenceEngine engine("model.onnx");
cv::Mat image = cv::imread("test.jpg");
auto prediction = engine.predict(image);
```

### Frontend API Call
```javascript
import { api } from './services/api';

// Get latest metrics
const metrics = await api.getMetrics('tensorflow_mobilenet');
console.log(metrics.accuracy); // 0.80
```

## Requirements

### Python
- Python 3.10+
- PyTorch 2.0+ with CUDA
- TensorFlow 2.18+ with GPU
- OpenCV 4.8+
- scikit-learn 1.3+

### C++
- C++17 compiler
- CMake 3.15+
- OpenCV 4.x
- ONNX Runtime 1.16+

### Frontend
- Node.js 18+
- React 18
- Vite 5

## Built with Kiro CLI

This project was **entirely developed using Kiro CLI**, Amazon Web Services' AI-powered development assistant. Kiro CLI enabled:

- **Rapid Development**: Complete system built systematically
- **Code Quality**: Professional-grade code generation
- **Multi-Language**: Seamless Python, C++, JavaScript integration
- **Best Practices**: Modern patterns and optimizations
- **Documentation**: Comprehensive guides generated
- **Testing**: Complete test suite developed
- **Production Ready**: Docker and deployment configs

**30+ systematic commits** demonstrate AI-assisted development workflow.

Learn more: [AWS Kiro](https://aws.amazon.com/)

## Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open Pull Request

## License

MIT License - see LICENSE file for details

## Acknowledgments

- PyTorch and TensorFlow teams
- ONNX Runtime developers
- OpenCV community
- React and FastAPI maintainers
- **Kiro CLI** - Amazon's AI development assistant

## Contact

GitHub: [@SkullKrak7](https://github.com/SkullKrak7)

---

**Status**: Production Ready | GPU Optimized | Docker Ready | Built with Kiro CLI | 30+ Commits
